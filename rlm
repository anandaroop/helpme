#! /usr/bin/env ruby

require 'dotenv'
require 'ruby_llm'

# find .env regardless of where this file is symlinked or run from

actual_path_to_this_file = (File.realpath(__FILE__))
this_dir = File.dirname(actual_path_to_this_file)
env_path = File.join(this_dir, '.env')
Dotenv.load(env_path)

# configure API keys

RubyLLM.configure do |config|
  config.anthropic_api_key = ENV['ANTHROPIC_API_KEY']
  config.openai_api_key = ENV['OPENAI_API_KEY']
end

# set up the chat completion

anthropic_chat = RubyLLM.chat(model: "claude-3-7-sonnet-20250219").with_temperature(0.1)
openai_chat = RubyLLM.chat(model: "gpt-4o-2024-05-13").with_temperature(0.1)

system_prompt = <<~SYSTEM
  You are an expert user of the following command line Unix utilities:
  - ffmpeg
  - imagemagick

  Your task is to take the user's request and produce the exact
  command line invocation that will accomplish the user's goal,
  including all necessary flags and arguments.

  Prefer ImageMagick over ffmpeg for image processing tasks.

  If you need more information from the user, state what's missing.

  Otherwise, no yapping, no markdown, no fluff. Just the command.
SYSTEM

anthropic_chat.add_message role: :system, content: system_prompt
openai_chat.add_message role: :system, content: system_prompt

# get the LLM response

user_request = ARGV.join(" ")

anthropic_response = anthropic_chat.ask user_request
anthropic_command = anthropic_response.content
puts "[anthropic] #{anthropic_command}"

openai_response = openai_chat.ask user_request
openai_command = openai_response.content
puts "[openai] #{openai_command}"

# maybe run the command

# print "Run this command? [y/N]: "
# if STDIN.gets =~ /^y/i
#   system anthropic_command
# end
