#! /usr/bin/env ruby

require 'dotenv/load'
require 'ruby_llm'

RubyLLM.configure do |config|
  # Required: At least one API key
  config.openai_api_key = ENV['OPENAI_API_KEY']
  config.anthropic_api_key = ENV['ANTHROPIC_API_KEY']
  # config.gemini_api_key = ENV['GEMINI_API_KEY']
  # config.deepseek_api_key = ENV['DEEPSEEK_API_KEY']

  # Optional: Set default models
  # config.default_model = 'gpt-4o-mini'               # Default chat model
  # config.default_embedding_model = 'text-embedding-3-small'  # Default embedding model
  # config.default_image_model = 'dall-e-3'            # Default image generation model

  # Optional: Configure request settings
  # config.request_timeout = 120  # Request timeout in seconds
  # config.max_retries = 3        # Number of retries on failures
end

# Check available models
puts "Available models:"
RubyLLM.models.chat_models.each do |model|
  puts "- #{model.id} (#{model.provider})"
end

# Try a simple query
chat = RubyLLM.chat
response = chat.ask "Hello, world!"
puts response.content

